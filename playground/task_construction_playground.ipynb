{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nHere's a guide on optional typing in python:\\nhttps://medium.com/@ageitgey/learn-how-to-use-static-type-checking-in-python-3-6-in-10-minutes-12c86d72677b\\n\\nI don't claim to be doing it perfectly, but I'm working on it. \\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from typing import Dict, Tuple\n",
    "\"\"\"\n",
    "Here's a guide on optional typing in python:\n",
    "https://medium.com/@ageitgey/learn-how-to-use-static-type-checking-in-python-3-6-in-10-minutes-12c86d72677b\n",
    "\n",
    "I don't claim to be doing it perfectly, but I'm working on it. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parameters:\n",
    "    \"\"\"\n",
    "    This is just a shell class to hold the parameters\n",
    "    \"\"\"\n",
    "    learning_rate: float = 0 #alpha, how quick the agent learns\n",
    "    discount_factor: float = 0 # discount rate\n",
    "    exploration_prob: float = 0 #epsilon\n",
    "    def __init__(self):\n",
    "        self.learning_rate = random.uniform(0, 1)\n",
    "        self.discount_faction = random.uniform(0, 1)\n",
    "    def set_params(self, learning_rate: float, discount_factor: float) -> None:\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        \n",
    "    def set_learning_rate(self, alpha: float) -> None:\n",
    "        self.learning_rate = alpha\n",
    "        \n",
    "    def set_discount_factor(self, gamma: float) -> None: \n",
    "        self.discount_factor = gamma\n",
    "        \n",
    "\n",
    "    def set_random_params(self) -> None:\n",
    "        self.__init__()\n",
    "        \n",
    "\n",
    "class task:\n",
    "    \"\"\"\n",
    "    This class is for a definition of a RL task. The items that \n",
    "    must be defined is an array of possible actions, a state space, \n",
    "    a probability distribution with each of the actions. \n",
    "    \"\"\"\n",
    "    actions: Dict[str, list] = []\n",
    "    states: list = []\n",
    "    rewards: Dict[str, str] = {}\n",
    "    def __init__(self, actions: Dict[str, str] = {}, states: list = [], prob_actions: Dict[str, float] = {}) -> None:\n",
    "        if actions == {}:\n",
    "            \"\"\"\n",
    "            This is the definition for the initial probabilistic rewards model\n",
    "            \"\"\"\n",
    "            self.states = [\"center\", \"left\", \"right\", \"left button pressed\", \"right buttton pressed\"]\n",
    "            self.actions = {\"center\": [\"m-left\", \"m-right\"], \"left\": [\"m-right\", \"press-left\"], \"right\": [\"m-left\", \"press-right\"]}\n",
    "            self.rewards = {\"m-left\": -1, \"m-right\": -1, \"press-left\": np.random.choice([10, -1], p = [.8, .2]), \"press-right\": np.random.choice([10, -1], p = [.2, .8])}\n",
    "        else:    \n",
    "            self.actions = actions\n",
    "            self.states = states\n",
    "            self.prob_actions = prob_actions\n",
    "        \n",
    "class q_learning_agent:\n",
    "    \"\"\"\n",
    "    This is the agent that implements q learning. It will \n",
    "    need a task and a set of parameters (using their respective classes)\n",
    "    \"\"\"\n",
    "    params = None\n",
    "    task = None\n",
    "    policy = None\n",
    "    qValues = None\n",
    "    def __init__(task: task, params = parameters()) -> None:\n",
    "        self.task = task\n",
    "        self.params = params\n",
    "        self.qValues = {}\n",
    "        \n",
    "    def getqvalue(self, state: str, action: str):\n",
    "        pass\n",
    "    \n",
    "    def compute_value_from_q(self, state):\n",
    "        pass\n",
    "    \n",
    "    def compute_action_from_q(self, state):\n",
    "        pass\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        pass\n",
    "    \n",
    "    def update_q_values(self, state, action, nextstate, reward):\n",
    "        pass\n",
    "        \n",
    "    def run() -> list:\n",
    "        \"\"\"\n",
    "        This will run the given parameters on the given \n",
    "        task -- the task should contain the gridworld and everything \n",
    "        else needed. It will return the policy, but this will also be stored \n",
    "        as a class variable, so it can be accessed at a later time.\n",
    "        \"\"\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m-left': -1, 'm-right': -1, 'press-left': -1, 'press-right': -1}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = task()\n",
    "t.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2, 2. , 1.2, ..., 1.2, 2. , 1.2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_contents = sio.loadmat('../data/pilot_data_2odor_8020prob.mat')\n",
    "mat_contents['group_setsize2_result'][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
